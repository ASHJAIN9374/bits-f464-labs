{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtMNLQb6_9WA"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJQ-bKpZGRCF"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFdabDFy_J5j"
      },
      "outputs": [],
      "source": [
        "class LinearModel(object):\n",
        "    \"\"\"\n",
        "    Base class for linear models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, step_size=0.2, max_iter=100, eps=1e-5,\n",
        "                 theta_0=None, verbose=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            step_size: Step size for iterative solvers only.\n",
        "            max_iter: Maximum number of iterations for the solver.\n",
        "            eps: Threshold for determining convergence.\n",
        "            theta_0: Initial guess for theta. If None, use the zero vector.\n",
        "            verbose: Print loss values during training.\n",
        "        \"\"\"\n",
        "        self.theta = theta_0\n",
        "        self.step_size = step_size\n",
        "        self.max_iter = max_iter\n",
        "        self.eps = eps\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        \"\"\"\n",
        "        Run solver to fit linear model.\n",
        "\n",
        "        Args:\n",
        "            x: Training example inputs. Shape (m, n).\n",
        "            y: Training example labels. Shape (m,).\n",
        "        \"\"\"\n",
        "        raise NotImplementedError('Subclass of LinearModel must implement fit method.')\n",
        "\n",
        "    def transform(self, x):\n",
        "        \"\"\"\n",
        "        Transforms the input data to the feature space learned from the training data.\n",
        "\n",
        "        Args:\n",
        "            x: Inputs of shape (m, n).\n",
        "\n",
        "        Returns:\n",
        "            Transformed inputs of shape (m, n').\n",
        "        \"\"\"\n",
        "        raise NotImplementedError('Subclass of LinearModel must implement transform method.')\n",
        "\n",
        "    def set_params(self, **kwargs):\n",
        "        \"\"\"Set the parameters of this model.\n",
        "\n",
        "        Args:\n",
        "            **kwargs: A dictionary of parameters and their values.\n",
        "        \"\"\"\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        Make a prediction given new inputs x.\n",
        "\n",
        "        Args:\n",
        "            x: Inputs of shape (m, n).\n",
        "\n",
        "        Returns:\n",
        "            Outputs of shape (m,).\n",
        "        \"\"\"\n",
        "        raise NotImplementedError('Subclass of LinearModel must implement predict method.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vXqELlpVqQT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def add_intercept(x):\n",
        "    \"\"\"Add intercept to matrix x.\n",
        "\n",
        "    Args:\n",
        "        x: 2D NumPy array.\n",
        "\n",
        "    Returns:\n",
        "        New matrix same as x with 1's in the 0th column.\n",
        "    \"\"\"\n",
        "    new_x = np.zeros((x.shape[0], x.shape[1] + 1), dtype=x.dtype)\n",
        "    new_x[:, 0] = 1\n",
        "    new_x[:, 1:] = x\n",
        "\n",
        "    return new_x\n",
        "\n",
        "\n",
        "def load_dataset(csv_path, label_col='y', add_intercept=False):\n",
        "    \"\"\"Load dataset from a CSV file.\n",
        "\n",
        "    Args:\n",
        "         csv_path: Path to CSV file containing dataset.\n",
        "         label_col: Name of column to use as labels (should be 'y' or 't').\n",
        "         add_intercept: Add an intercept entry to x-values.\n",
        "\n",
        "    Returns:\n",
        "        xs: Numpy array of x-values (inputs).\n",
        "        ys: Numpy array of y-values (labels).\n",
        "    \"\"\"\n",
        "\n",
        "    def add_intercept_fn(x):\n",
        "        global add_intercept\n",
        "        return add_intercept(x)\n",
        "\n",
        "    # Validate label_col argument\n",
        "    allowed_label_cols = ('y', 't')\n",
        "    if label_col not in allowed_label_cols:\n",
        "        raise ValueError('Invalid label_col: {} (expected {})'\n",
        "                         .format(label_col, allowed_label_cols))\n",
        "\n",
        "    # Load headers\n",
        "    with open(csv_path, 'r') as csv_fh:\n",
        "        headers = csv_fh.readline().strip().split(',')\n",
        "\n",
        "    # Load features and labels\n",
        "    x_cols = [i for i in range(len(headers)) if headers[i].startswith('x')]\n",
        "    l_cols = [i for i in range(len(headers)) if headers[i] == label_col]\n",
        "    inputs = np.loadtxt(csv_path, delimiter=',', skiprows=1, usecols=x_cols)\n",
        "    labels = np.loadtxt(csv_path, delimiter=',', skiprows=1, usecols=l_cols)\n",
        "\n",
        "    if inputs.ndim == 1:\n",
        "        inputs = np.expand_dims(inputs, -1)\n",
        "\n",
        "    if add_intercept:\n",
        "        inputs = add_intercept_fn(inputs)\n",
        "\n",
        "    return inputs, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgwosIVrGtmP"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUfS7wjiVlO7"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbutjwPtVnUE"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = load_dataset('ds1_train.csv', add_intercept=True)\n",
        "x_eval, y_eval = load_dataset('ds1_valid.csv', add_intercept=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ff4nF4NWECW"
      },
      "source": [
        "### In `sklearn` format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPAHuUOCGvLF"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(LinearModel):\n",
        "    \"\"\"Logistic regression with Newton's Method as the solver.\n",
        "\n",
        "    Example usage:\n",
        "        > clf = LogisticRegression()\n",
        "        > clf.fit(x_train, y_train)\n",
        "        > clf.predict(x_eval)\n",
        "    \"\"\"\n",
        "\n",
        "    def transform(self, x):\n",
        "\n",
        "      return x\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        \"\"\"Run Newton's Method to minimize J(theta) for logistic regression.\n",
        "\n",
        "        Args:\n",
        "            x: Training example inputs. Shape (m, n).\n",
        "            y: Training example labels. Shape (m,).\n",
        "        \"\"\"\n",
        "        m, n = x.shape\n",
        "        self.theta = np.zeros(n)\n",
        "\n",
        "        while True:\n",
        "\n",
        "            old_theta = self.theta\n",
        "\n",
        "            hx = 1/(1 + np.exp(-x.dot(self.theta)))\n",
        "            H = (x.T * hx * (hx - 1)).dot(x)/m\n",
        "            grad_l = x.T.dot(y - hx)/m\n",
        "\n",
        "            self.theta = self.theta - np.linalg.inv(H).dot(grad_l)\n",
        "\n",
        "            if(np.linalg.norm(self.theta-old_theta, ord=1) < self.eps):\n",
        "                break\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"Make a prediction given new inputs x.\n",
        "\n",
        "        Args:\n",
        "            x: Inputs of shape (m, n).\n",
        "\n",
        "        Returns:\n",
        "            Outputs of shape (m,).\n",
        "        \"\"\"\n",
        "        hx = x.dot(self.theta)\n",
        "        hx = 1/(1 + np.exp(-hx))\n",
        "\n",
        "        return hx\n",
        "\n",
        "    def score(self, x, y):\n",
        "        \"\"\"\n",
        "        Return accuracy of model on a given dataset (x, y).\n",
        "\n",
        "        Args:\n",
        "            x: Inputs of shape (m, n).\n",
        "            y: Outputs of shape (m,).\n",
        "\n",
        "        Returns:\n",
        "            Accuracy (between 0.0 and 1.0).\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(x)\n",
        "        return (y_pred == y).sum()/len(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrE9JL1wY_K1"
      },
      "source": [
        "### Train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VEZFMCWYzX6"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_eval) > 0.5\n",
        "print(f\"Achieved {100*(y_pred == y_eval).sum()/len(y_eval):.2f}% accuracy.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ipCtW35Z-Gr"
      },
      "source": [
        "### But what's the big talk of using sklearn? I'll talk about `pipelines`, which are very similar to `nn.Sequential` or `keras.Sequential` and so reduces a lot of coding on our part, check out the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFo7Q7s8azze"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-learn\n",
        "import sklearn\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mjNHB9EeK9B"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = load_dataset('ds1_train.csv', add_intercept=False)\n",
        "x_eval, y_eval = load_dataset('ds1_valid.csv', add_intercept=False)\n",
        "# try add_intercept=True, can you guess why it fails?!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9i8Kbm4bCSw"
      },
      "outputs": [],
      "source": [
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('estimator', LogisticRegression())])\n",
        "pipe.fit(x_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(x_eval) > 0.5\n",
        "print(f\"Achieved {100*(y_pred == y_eval).sum()/len(y_eval):.2f}% accuracy.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjS50c97gLUv"
      },
      "source": [
        "### Although the accuracy dropped but this helps with writing (annoying) Cross Validation code!\n",
        "Note the '__' and the warnings, which are fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnV-9zgOfxw2"
      },
      "outputs": [],
      "source": [
        "param_grid = {\"estimator__step_size\":[1, 0.1, 1e-3, 1e-4]}\n",
        "search = GridSearchCV(pipe, param_grid, scoring='accuracy')\n",
        "search.fit(x_train, y_train)\n",
        "\n",
        "print(search.best_params_)\n",
        "\n",
        "y_pred = search.best_estimator_.predict(x_eval) > 0.5\n",
        "print(f\"Achieved {100*(y_pred == y_eval).sum()/len(y_eval):.2f}% accuracy.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VxYMzQUpP3h"
      },
      "source": [
        "## Poisson regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1g2XIHqpY-p"
      },
      "source": [
        "### You have to basically implement the full above pipeline (not just the pipeline!) add data, write the `.fit()` function and `.predict()` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWdIqXdepxWj"
      },
      "source": [
        "### Poisson regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujkv_Ux_pSqE"
      },
      "outputs": [],
      "source": [
        "class PoissonRegression(LinearModel):\n",
        "    \"\"\"\n",
        "    Poisson Regression.\n",
        "\n",
        "    Example usage:\n",
        "        > clf = PoissonRegression(step_size=lr)\n",
        "        > clf.fit(x_train, y_train)\n",
        "        > clf.predict(x_eval)\n",
        "    \"\"\"\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        \"\"\"\n",
        "        Run gradient ascent to maximize likelihood for Poisson regression.\n",
        "\n",
        "        Args:\n",
        "            x: Training example inputs. Shape (m, n).\n",
        "            y: Training example labels. Shape (m,).\n",
        "        \"\"\"\n",
        "        # *** START CODE HERE ***\n",
        "        \n",
        "        # *** END CODE HERE ***\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        Make a prediction given inputs x.\n",
        "\n",
        "        Args:\n",
        "            x: Inputs of shape (m, n).\n",
        "\n",
        "        Returns:\n",
        "            Floating-point prediction for each input, shape (m,).\n",
        "        \"\"\"\n",
        "        # *** START CODE HERE ***\n",
        "        # *** END CODE HERE ***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUiYKmtzp30k"
      },
      "source": [
        "### Train!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJZ4hzlhqIqw"
      },
      "source": [
        "This tutorial was made by Karan, and borrows from the official <a href=\"https://scikit-learn.org/stable/\">SciKit learn Docs</a>."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
